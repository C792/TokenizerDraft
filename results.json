[
  {
    "tokenizer": "WordTokenizer",
    "vocab_size": 1572,
    "total_tokens": 2631,
    "avg_tokens_per_sentence": 15.476470588235294,
    "compression_ratio_chars_per_token": 4.706195362979855,
    "time_ms_tokenize": 0.5653000007441733
  },
  {
    "tokenizer": "CharTokenizer",
    "vocab_size": 376,
    "total_tokens": 12382,
    "avg_tokens_per_sentence": 72.83529411764705,
    "compression_ratio_chars_per_token": 1.0,
    "time_ms_tokenize": 0.7695999993302394
  },
  {
    "tokenizer": "BPETokenizer",
    "vocab_size": 3157,
    "total_tokens": 5565,
    "avg_tokens_per_sentence": 32.73529411764706,
    "compression_ratio_chars_per_token": 2.2249775381850854,
    "time_ms_tokenize": 1326.9098999990092
  }
]